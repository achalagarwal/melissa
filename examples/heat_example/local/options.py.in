###################################################################
#                            Melissa                              #
#-----------------------------------------------------------------#
#   COPYRIGHT (C) 2017  by INRIA and EDF. ALL RIGHTS RESERVED.    #
#                                                                 #
# This source is covered by the BSD 3-Clause License.             #
# Refer to the  LICENCE file for further information.             #
#                                                                 #
#-----------------------------------------------------------------#
#  Original Contributors:                                         #
#    Theophile Terraz,                                            #
#    Bruno Raffin,                                                #
#    Alejandro Ribes,                                             #
#    Bertrand Iooss,                                              #
###################################################################


"""
    User defined options module
"""
import os
import time
import numpy as np
import subprocess
import getpass
import imp
import socket
#from matplotlib import pyplot as plt
#from matplotlib import cm
from string import Template
from shutil import copyfile

# These variables are only used in this file.
USERNAME = getpass.getuser()
BUILD_WITH_MPI = '@BUILD_WITH_MPI@'.upper()
BUILD_WITH_FLOWVR = '@BUILD_WITH_FLOWVR@'.upper()
EXECUTABLE='heatc'
NODES_SERVER = 1
NODES_GROUP = 1
WALLTIME_SERVER = 600
WALLTIME_SIMU = 300

# The launch_server function to put in USER_FUNCTIONS['launch_server'].
# It takes a Server object as argument, and must set its job_id attribute.
# Here, we use the PID of the subprocess.
# The server object provides two important attributes:
#   path: the path to melissa_server executable
#   cmd_opt: the options set by the launcher to pass to the server.

def launch_server(server):
    if (not os.path.isdir(STUDY_OPTIONS['working_directory'])):
        os.mkdir(STUDY_OPTIONS['working_directory'])
    os.chdir(STUDY_OPTIONS['working_directory'])
    print 'mpirun ' + ' -n '+str(NODES_SERVER) + ' ' + server.path + '/melissa_server ' + server.cmd_opt + ' &'
    server.job_id = subprocess.Popen(('mpirun ' +
                                      ' -n '+str(NODES_SERVER) +
                                      ' ' + server.path +
                                      '/melissa_server.py ' +
                                      server.cmd_opt +
                                      ' &').split()).pid
    #server.job_id = subprocess.Popen(('mpirun ' +
                                      #' -n '+str(NODES_SERVER) +
                                      #' ' + server.path +
                                      #'/melissa_server.py ' +
                                      #server.cmd_opt +
                                      #' &').split()).pid
    os.chdir(STUDY_OPTIONS['working_directory'])

# The launch_group function to put in USER_FUNCTIONS['launch_group'].
# It is used to launch batches of simulations (or groups of simulation the case of Sobol' indices computation).
# It takes a Group object as argument, and must set the job ID of the group of simulations in the attribute job_id of the Group object.
# This object provides three important attributes:
#   simu_id:
#   rank
#   param_set
# We distinguish three kinds of groups:

# Once we have set the job IDs of our jobs, we can use it to define the fault tolerance functions. In our case, we will use the same function for the server and the simulations. It takes a `Job` object as argument, and sets its `status` attribute to 0 if it is waiting to be scheduled, 1 if it is currently running, or 2 if it is not running anymore. In your local machine, a job will never be have a 0 status, because it is launched immediately when `USER_FUNCTIONS['launch_group']` is called.

def launch_group(group):
    if (not os.path.isdir(STUDY_OPTIONS['working_directory']+"/group"+str(group.rank))):
        os.mkdir(STUDY_OPTIONS['working_directory']+"/group"+str(group.rank))
    os.chdir(STUDY_OPTIONS['working_directory']+"/group"+str(group.rank))
    os.environ['MELISSA_SERVER_NODE_NAME'] = group.server_node_name

    if MELISSA_STATS['sobol_indices']:

        # Sobol group: In the case of Sobol' indices computation, all the simulations of a Sobol' group must be in the same job.
        # In that case, simu_id is a list of the simulation IDs inside the Sobol' group (the ones you will pass to melissa_init), and rank is the ID of the group.
        # param_set is a list of size STUDY_OPTIONS['nb_parameters'] + 2 of numpy arrays of size STUDY_OPTIONS['nb_parameters'], corresponding to the sets of n parameters of the n+2 simulations in the Sobol' group.

        if BUILD_WITH_FLOWVR == 'ON' and STUDY_OPTIONS['coupling'] == 'MELISSA_COUPLING_FLOWVR':
            args = []
            for i in range(STUDY_OPTIONS['nb_parameters'] + 2):
                args.append(str(group.simu_id[i])+" "+ str(group.coupling)+" "+' '.join(str(j) for j in group.param_set[i]))
            content = ""
            file=open("@EXAMPLES_DIR@/heat_example/study_local/scripts/flowvr_group.py", "r")
            content = Template(file.read()).substitute(args=str(args),
                               group_id=str(group.rank),
                               np_simu=str(int(NODES_GROUP)),
                               nb_param=str(STUDY_OPTIONS['nb_parameters']),
                               executable='@EXAMPLES_DIR@/heat_example/solver/install/bin/'+EXECUTABLE)
            file.close()
            file=open("create_group"+str(group.rank)+".py", "w")
            file.write(content)
            file.close()
            os.system('python create_group'+str(group.rank)+'.py')
            group.job_id = subprocess.Popen('flowvr group'+str(group.rank), shell=True).pid
        else:
            os.environ['MELISSA_MASTER_NODE_NAME'] = socket.gethostname()
            command = 'mpirun '
            for i in range(STUDY_OPTIONS['nb_parameters'] + 2):
                command += ' '.join(('-n',
                                     str(NODES_GROUP),
                                     '@EXAMPLES_DIR@/heat_example/solver/install/bin/'+EXECUTABLE,
                                     str(group.simu_id[i]), str(group.coupling),
                                     ' '.join(str(j) for j in group.param_set[i]),
                                     ': '))
            print command[:-2]
            group.job_id = subprocess.Popen(command[:-2].split()).pid

    elif STUDY_OPTIONS['batch_size'] > 1:

        # Batch of simulations: Multiple simulations are launched in the same job.
        # In that case, simu_id is a list of the simulation IDs of size STUDY_OPTIONS['batch_size'] (the ones you will pass to melissa_init in your solver), and rank is the ID of the group.
        # param_set is a list of size STUDY_OPTIONS['batch_size'] of numpy arrays of size STUDY_OPTIONS['nb_parameters'].
        # The parameter STUDY_OPTIONS['sampling_size'] must be a multiple of STUDY_OPTIONS['batch_size'].

        command = 'mpirun '
        for i in range(group.size):
            command += ' '.join(('-n',
                                 str(NODES_GROUP),
                                 '@EXAMPLES_DIR@/heat_example/solver/install/bin/'+EXECUTABLE,
                                 str(group.simu_id[i]),
                                 str(group.coupling),
                                 ' '.join(str(j) for j in group.param_set[i]),
                                 ': '))
        print command[:-2]
        os.environ['MELISSA_MASTER_NODE_NAME'] = socket.gethostname()
        group.job_id = subprocess.Popen(command[:-2].split()).pid

    else:

        # Single simulation (general case): Every simulation has its own job.
        # In this case, simu_id and rank are equivalents, and param_set is a numpy array of size STUDY_OPTIONS['nb_parameters'].

        if BUILD_WITH_MPI == 'ON':
            command = ' '.join(('mpirun',
                                 '-n',
                                 str(NODES_GROUP),
                                 '@EXAMPLES_DIR@/heat_example/solver/install/bin/'+EXECUTABLE,
                                 str(group.simu_id),
                                 str(group.coupling),
                                 ' '.join(str(i) for i in group.param_set)))
        else:
            command = ' '.join(('@EXAMPLES_DIR@/heat_example/solver/install/bin/'+EXECUTABLE,
                                str(0),
                                str(group.simu_id),
                                str(group.coupling),
                                ' '.join(str(i) for i in group.param_set)))
        print command

        # We set the job_id attribute of the Group object.

        group.job_id = subprocess.Popen(command.split()).pid
    os.chdir(STUDY_OPTIONS['working_directory'])

def check_job(job):
    # Check the job state:
    # 0: not runing
    # 1: running
    # 2: not running anymore (finished or crashed)
    state = 0
    try:
        subprocess.check_output(["ps",str(job.job_id)])
        state = 1
    except:
        state = 2
    # we set the job_status attribute of the Job object. Group and Server objects inherite of Job.
    job.job_status = state

def check_load():
    # We only run one group at a time
    #time.sleep(1)
    try:
        subprocess.check_output(["pidof",EXECUTABLE])
        return False
    except:
        return True

def kill_job(job):
    os.system('kill '+str(job.job_id))

def draw_param_set():
    # draw a numpy array of size STUDY_OPTIONS['nb_parameters']
    param_set = np.zeros(STUDY_OPTIONS['nb_parameters'])
    for i in range(STUDY_OPTIONS['nb_parameters']):
        param_set[i] = np.random.uniform(0, 1)
    return param_set

STUDY_OPTIONS = {}
STUDY_OPTIONS['user_name'] = USERNAME
STUDY_OPTIONS['working_directory'] = '@EXAMPLES_DIR@/heat_example/study_local/STATS'
STUDY_OPTIONS['nb_parameters'] = 5                 # number of varying parameters of the study
STUDY_OPTIONS['sampling_size'] = 100               # initial number of parameter sets
STUDY_OPTIONS['nb_time_steps'] = 100               # number of timesteps, from Melissa point of view
STUDY_OPTIONS['threshold_values'] = 0.7
STUDY_OPTIONS['quantile_values'] = [0.05,0.25,0.5,0.75,0.95]
STUDY_OPTIONS['field_names'] = ["heat1"]           # list of field names
STUDY_OPTIONS['simulation_timeout'] = 40           # simulations are restarted if no life sign for 40 seconds
STUDY_OPTIONS['checkpoint_interval'] = 100          # server checkpoints every 30 seconds
STUDY_OPTIONS['coupling'] = "MELISSA_COUPLING_MPI" # option for Sobol' simulation groups coupling
STUDY_OPTIONS['verbosity'] = 2                     # verbosity: 0: only errors, 1: errors + warnings, 2: usefull infos (default), 3: debug infos
STUDY_OPTIONS['batch_size'] = 5
STUDY_OPTIONS['learning'] = False

MELISSA_STATS = {}
MELISSA_STATS['mean'] = False
MELISSA_STATS['variance'] = False
MELISSA_STATS['skewness'] = False
MELISSA_STATS['kurtosis'] = False
MELISSA_STATS['min'] = False
MELISSA_STATS['max'] = False
MELISSA_STATS['threshold_exceedance'] = True
MELISSA_STATS['quantiles'] = False
MELISSA_STATS['sobol_indices'] = True

USER_FUNCTIONS = {}
USER_FUNCTIONS['create_study'] = None
USER_FUNCTIONS['draw_parameter_set'] = draw_param_set
USER_FUNCTIONS['create_group'] = None
#if MELISSA_STATS['sobol_indices']:
#    USER_FUNCTIONS['launch_group'] = launch_group
#else:
USER_FUNCTIONS['launch_group'] = launch_group
USER_FUNCTIONS['launch_server'] = launch_server
USER_FUNCTIONS['check_server_job'] = check_job
USER_FUNCTIONS['check_group_job'] = check_job
USER_FUNCTIONS['restart_server'] = launch_server
USER_FUNCTIONS['restart_group'] = None
USER_FUNCTIONS['check_scheduler_load'] = check_load
USER_FUNCTIONS['cancel_job'] = kill_job
USER_FUNCTIONS['postprocessing'] = None
USER_FUNCTIONS['finalize'] = None
