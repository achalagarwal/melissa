#!@PYTHON_EXECUTABLE@

###################################################################
#                            Melissa                              #
#-----------------------------------------------------------------#
#   COPYRIGHT (C) 2017  by INRIA and EDF. ALL RIGHTS RESERVED.    #
#                                                                 #
# This source is covered by the BSD 3-Clause License.             #
# Refer to the  LICENCE file for further information.             #
#                                                                 #
#-----------------------------------------------------------------#
#  Original Contributors:                                         #
#    Theophile Terraz,                                            #
#    Bruno Raffin,                                                #
#    Alejandro Ribes,                                             #
#    Bertrand Iooss,                                              #
###################################################################

# -*- coding: utf-8 -*-

"""
    Python sequential version of melissa_server.

    usage:
    python melissa_server.py <options>
"""

from __future__ import absolute_import, division
#from __future__ import print_function
import tensorflow as tf
import os
import time
import sys
import signal
import imp
import getopt
import numpy as np
import ctypes
import MEDLoader as ml
import MEDCoupling as mc
from mpi4py import MPI

import matplotlib.pyplot as plt

# Set Eager API
tf.enable_eager_execution()
tfe = tf.contrib.eager

melissa_server = np.ctypeslib.load_library('libmelissa_server4py','@CMAKE_INSTALL_PREFIX@/lib/')

c_char_ptr = ctypes.POINTER(ctypes.c_char)
c_char_ptr_ptr = ctypes.POINTER(c_char_ptr)
c_double_ptr = ctypes.POINTER(ctypes.c_double)
c_void_ptr_ptr = ctypes.POINTER(ctypes.c_void_p)

# size of the training and testing batches
BATCH_SIZE = 20

# Class to transfer data between Python and C
class simulation_data(ctypes.Structure):
    _fields_ = [("simu_id", ctypes.c_int),
                ("parameters", c_double_ptr),
                ("nb_param", ctypes.c_int),
                ("time_stamp", ctypes.c_int),
                ("first_init", ctypes.c_int),
                ("status", ctypes.c_int),
                ("val", c_double_ptr),
                ("val_size", ctypes.c_int),
                ("max_val_size", ctypes.c_int)]

class melissa_helper_tf:
    def __init__(self, nb_parameters):
        self.train_x = []
        self.train_y = []
        self.test_x = []
        self.test_y = []
        self.nb_parameters = nb_parameters

def add_to_training_set(x, y, handle):
    handle.train_y.append(np.array(y))
    handle.train_x.append(np.array(x))

def add_to_testing_set(x, y, handle):
    handle.test_y.append(np.array(y))
    handle.test_x.append(np.array(x))


def neighbors_MED():
    indices = []
    mesh = ml.ReadUMeshFromFile("/home/tterraz/Documents/deep_learning_subashuny/final_output/von_karman/MESH/COARSE/Cylinder_7361.med","Cylinder_1",0)
    tab1, tab2 = mesh.computeNeighborsOfCells()
    for i in range(len(tab2)-1): # cell
        diag_inserted = False
        for k in tab1[tab2[i]:tab2[i+1]]: # neighbors
            if k[0] > i and not diag_inserted:
                indices.append([i,i])
                diag_inserted = True
            indices.append([i,k[0]])
        if not diag_inserted:
            indices.append([i,i])
    return indices

def neighbors_read():
    indices = [[0, 0]]
    file = open("VKindices", "r")
    for line in file:
        indices.append([int(i) for i in line.split()])
    file.close()
    return indices

def neighbors_write(indices):
    file = open("VKindices", "w")
    for i in indices:
        file.write(str(i[0])+" "+str(i[1])+"\n")
    file.close()

def neighbors_square(size):
    x = int(np.sqrt(size))
    y = int(np.sqrt(size))
    indices = []
    for i in range(size): # row
        k = i%x # col
        l = np.floor(i/x) # row
        indices.append([i,i])
        if l > 0:
            indices.append([i,i-x])
        if k > 0:
            indices.append([i,i-1])
        if k < x-1:
            indices.append([i,i+1])
        if l < y-1:
            indices.append([i,i+x])
    return indices

class MySparseLayer(tf.keras.layers.Layer):
    def __init__(self, size, trainable=True):
        super(MySparseLayer, self).__init__()
        self.size = size
        self.indices = neighbors_square(size)
        #self.indices = reighbors_read()
        #print "value shape: " + str(self.sparse_tensor.values.shape)
        #print "indices: " + str(self.sparse_tensor.indices)
        indice_size = len(self.indices)
        self.values = self.add_variable("values",
                                         shape=[len(self.indices)],
                                         dtype=tf.float64)
        self.biases = self.add_variable("biases", shape=[self.size], dtype=tf.float64, trainable=True)
        print self.variables

    def compute_output_shape(self, input_shape):
        return (input_shape[0], self.size)

    def call(self, input):
        sparse_tensor = tf.SparseTensor(self.indices, self.values.read_value(), [self.size, self.size])
        return tf.nn.relu(tf.nn.bias_add(tf.linalg.transpose(tf.sparse_tensor_dense_matmul(sparse_tensor, tf.linalg.transpose(input))), self.biases))


class MySparseLayer2(tf.keras.layers.Layer):
    def __init__(self, vect_size, trainable=True):
        super(MySparseLayer2, self).__init__()
        self.size = vect_size
        self.indices = neighbours_square(self.size)
        #print "value shape: " + str(self.sparse_tensor.values.shape)
        #print "indices: " + str(self.sparse_tensor.indices)
        self.values = self.add_variable("values",
                                         shape=[len(self.indices)],
                                         dtype=tf.float64)
        self.biases = self.add_variable("biases", shape=[self.size], dtype=tf.float64, trainable=True)

    def compute_output_shape(self, input_shape):
        return (input_shape[0], self.size)

    def call(self, input):
        out = np.zeros(input.shape)
        print type(out)
        print out.shape
        for i in range(len(self.indices)):
            out[:, self.indices[i][0]] = tf.multiply(input[:, self.indices[i][1]], self.values[i])
        return tf.nn.relu(tf.nn.bias_add(out, self.biases))

# Define the neural network. To use eager API and tf.layers API together,
# we must instantiate a tfe.Network class as follow:
class NeuralNet(tfe.Network):
    def __init__(self, input_size, vect_size):
        # Define each layer
        super(NeuralNet, self).__init__()
        self.input_size = input_size
        self.my_layers = []
        self.out_layers = []
        #self.x = x
        #self.y = y
        self.output_size = vect_size
        self.layer_dense = self.track_layer(tf.layers.Dense(self.output_size, activation=tf.nn.relu, trainable = False))
        #for i in range(50):
            #self.my_layers.append(tf.layers.Conv1D(1,
                                                   #5,
                                                   #padding='same'))
            ##self.my_layers.append(MySparseLayer(x, y))
        for i in range(30):
            self.out_layers.append(MySparseLayer(vect_size))

    def call(self, x):
        x = self.layer_dense(x)
        x = tf.reshape(x, [-1, self.output_size, 1])
        x_saved = x
        #for i in range(len(self.my_layers)):
            #x = self.my_layers[i](x)
            #if (i%2 == 0 and i > 0):
                #x = tf.add(x, x_saved)
                #x_saved = x

        #return tf.reshape(self.out_layer(x), [-1, self.output_size])
        x = tf.reshape(x, [-1, self.output_size])
        for i in range(len(self.out_layers)):
            x = self.out_layers[i](x)
        return x




# loss function
def loss_fn(inference_fn, params, labels):
    prediction = inference_fn(params)
    correct_pred = tf.square(prediction - labels)
    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))

# Calculate accuracy
def accuracy_fn(inference_fn, prediction, labels):
    correct_pred = tf.square(prediction - labels)
    return tf.reduce_max(tf.cast(correct_pred, tf.float32))


def main():

    # handle to a simulation_data structure that will travel between the C calls
    simu_data_ptr = ctypes.POINTER(simulation_data)

    # C prototypes
    melissa_server.melissa_server_init.argtypes = (ctypes.c_int, # argc
                                                   c_char_ptr_ptr, # argv
                                                   c_void_ptr_ptr)

    melissa_server.melissa_server_run.argtypes = (c_void_ptr_ptr,
                                                  simu_data_ptr)

    melissa_server.melissa_server_finalize.argtypes = (c_void_ptr_ptr,
                                                       simu_data_ptr)

    # get the command line
    argc = len(sys.argv)
    argv = (c_char_ptr * (argc + 1))()
    for i, arg in enumerate(sys.argv):
        enc_arg = arg.encode('utf-8')
        argv[i] = ctypes.create_string_buffer(enc_arg)

    #create a handle for the internal server structure (noc used in the Python side)
    simu_handle = ctypes.c_void_p()

    data = simulation_data()

    #init the server
    melissa_server.melissa_server_init(argc,
                                       argv,
                                       ctypes.byref(simu_handle))

    #run the server, only the first iteration if learning enabled
    melissa_server.melissa_server_run(ctypes.byref(simu_handle),
                                      ctypes.byref(data))

    ctypes.pythonapi.PyBuffer_FromMemory.restype = ctypes.py_object

    #get the data from the C structure
    server_status = getattr(data, 'status')
    if server_status == 0:
        vect_size = getattr(data, 'val_size')
        buff_val = ctypes.pythonapi.PyBuffer_FromMemory(getattr(data, 'val'), 8*vect_size)
        val_array = np.frombuffer(buff_val, float)
        nb_parameters = getattr(data, 'nb_param')
        buff_param = ctypes.pythonapi.PyBuffer_FromMemory(getattr(data, 'parameters'), 8*nb_parameters)
        param_array = np.frombuffer(buff_param, float)
        param_array = np.append(param_array, float(getattr(data, 'time_stamp'))/100)
        #param_array = np.expand_dims(param_array, axis=1)


    i = 0
    j = 0
    k = 0
    average_loss = 0.
    average_acc = 0.
    model_is_init = False
    learning_rate = 0.001
    learning_handle = melissa_helper_tf(nb_parameters)
    # adam Optimizer
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
    # Compute gradients
    grad = tfe.implicit_gradients(loss_fn)
    checkpoint_dir = './'
    checkpoint_prefix = checkpoint_dir + 'nn'

    #The while loop is executed only when doing learning.
    while server_status != 1:
        if server_status == 0:
            if not model_is_init:
                # Parameters

                accuracy = []
                #neural_net = NeuralNet(nb_parameters+1, vect_size)
                neural_net = NeuralNet(nb_parameters+1, vect_size)
                #neural_net = create_model(nb_parameters+1, vect_size)
                print "vect_size: "+str(vect_size)

                model_is_init = True
                add_to_training_set(param_array, val_array, learning_handle)
                i += 1

            melissa_server.melissa_server_run(ctypes.byref(simu_handle),
                                              ctypes.byref(data))

            #get the data from the C structure. For now, doesn't work for multiple fields
            server_status = getattr(data, 'status')
            buff_val = ctypes.pythonapi.PyBuffer_FromMemory(getattr(data, 'val'), 8*vect_size)
            val_array = np.frombuffer(buff_val, float)
            buff_param = ctypes.pythonapi.PyBuffer_FromMemory(getattr(data, 'parameters'), 8*getattr(data, 'nb_param'))
            param_array = np.frombuffer(buff_param, float)
            param_array = np.append(param_array, float(getattr(data, 'time_stamp'))/100)
            #param_array = np.expand_dims(param_array, axis=1)

            j += 1
            if j >= 10:
                #add one out of ten result to a testing batch
                add_to_testing_set(param_array, val_array, learning_handle)
                k += 1
                if k >= BATCH_SIZE:
                    # when the batch is ready, test on it
                    x_batch=np.stack(learning_handle.test_x, axis=0)
                    y_batch=np.stack(learning_handle.test_y, axis=0)
                    dataset = tf.data.Dataset.from_tensor_slices(
                        (x_batch, y_batch))
                    dataset = dataset.repeat().batch(BATCH_SIZE).prefetch(BATCH_SIZE)
                    dataset_iter = tfe.Iterator(dataset)
                    # Iterate through the dataset
                    d = dataset_iter.next()
                    # Images
                    x_batch = d[0]
                    # Labels
                    y_batch = tf.cast(d[1], dtype=tf.float64)

                    #print type(x_batch)
                    #print x_batch
                    #print x_batch.ndim

                    t1 = time.time()
                    prediction = neural_net(x_batch)
                    t2 = time.time()
                    print "eval_time=", "{:.9f}".format(t2-t1)
                    # Compute the batch accuracy
                    batch_accuracy = accuracy_fn(neural_net, prediction, y_batch)
                    accuracy.append(batch_accuracy.numpy())
                    batch_loss = batch_accuracy
                    average_loss += batch_loss
                    average_acc += batch_accuracy
                    learning_handle.test_x = []
                    learning_handle.test_y = []
                    average_loss /= BATCH_SIZE
                    average_acc /= BATCH_SIZE
                    print("test loss=",
                          "{:.9f}".format(average_loss), " accuracy=",
                          "{:.4f}".format(average_acc))
                    average_loss = 0.
                    average_acc = 0.
                    learning_handle.test_x = []
                    learning_handle.test_y = []
                    k = 0
                j = 0
            else:
                #add nine out of ten result to a training batch
                add_to_training_set(param_array, val_array, learning_handle)
                i += 1
                if i >= BATCH_SIZE:
                    # when the batch is ready, train on it
                    # Compute the batch loss
                    x_batch=np.stack(learning_handle.train_x, axis=0)
                    y_batch=np.stack(learning_handle.train_y, axis=0)
                    dataset = tf.data.Dataset.from_tensor_slices(
                        (x_batch, y_batch))
                    dataset = dataset.repeat().batch(BATCH_SIZE).prefetch(BATCH_SIZE)
                    dataset_iter = tfe.Iterator(dataset)
                    # Iterate through the dataset
                    d = dataset_iter.next()
                    # Images
                    x_batch = d[0]
                    # Labels
                    y_batch = tf.cast(d[1], dtype=tf.float64)

                    #print type(x_batch)
                    #print x_batch
                    #print x_batch.ndim

                    t1 = time.time()
                    prediction = neural_net(x_batch)
                    t2 = time.time()
                    print "eval_time=", "{:.9f}".format(t2-t1)
                    # Compute the batch accuracy
                    batch_accuracy = accuracy_fn(neural_net, prediction, y_batch)
                    accuracy.append(batch_accuracy.numpy())
                    batch_loss = batch_accuracy
                    average_loss += batch_loss
                    average_acc += batch_accuracy
                    t1 = time.time()
                    optimizer.apply_gradients(grad(neural_net, x_batch, y_batch))
                    t2 = time.time()
                    print "train_time=", "{:.9f}".format(t2-t1)
                    learning_handle.train_x = []
                    learning_handle.train_y = []
                    average_loss /= BATCH_SIZE
                    average_acc /= BATCH_SIZE
                    print("train loss=",
                          "{:.9f}".format(average_loss), " accuracy=",
                          "{:.4f}".format(average_acc))
                    average_loss = 0.
                    average_acc = 0.

                    i = 0
        elif server_status == 2:
            tf.contrib.eager.save_network_checkpoint(neural_net,checkpoint_prefix)
            melissa_server.melissa_server_run(ctypes.byref(simu_handle),
                                              ctypes.byref(data))

            #get the data from the C structure. For now, doesn't work for multiple fields
            server_status = getattr(data, 'status')
        elif server_status == 3:
            tf.contrib.eager.restore_network_checkpoint(neural_net,checkpoint_prefix)
            model_is_init = True
            add_to_training_set(param_array, val_array, learning_handle)
            i += 1
            melissa_server.melissa_server_run(ctypes.byref(simu_handle),
                                              ctypes.byref(data))

            #get the data from the C structure. For now, doesn't work for multiple fields
            server_status = getattr(data, 'status')

    print "end server"

    #clear the remaining train and test samples
    if i != 0:
        x_batch=np.stack(learning_handle.train_x, axis=0)
        y_batch=np.stack(learning_handle.train_y, axis=0)
        dataset = tf.data.Dataset.from_tensor_slices(
            (x_batch, y_batch))
        dataset = dataset.repeat().batch(i).prefetch(i)
        dataset_iter = tfe.Iterator(dataset)
        # Iterate through the dataset
        d = dataset_iter.next()
        # Images
        x_batch = d[0]
        # Labels
        y_batch = tf.cast(d[1], dtype=tf.float64)

        t1 = time.time()
        prediction = neural_net(x_batch)
        t2 = time.time()
        print "eval_time=", "{:.9f}".format(t2-t1)
        # Compute the batch accuracy
        batch_accuracy = accuracy_fn(neural_net, prediction, y_batch)
        t2 = time.time()
        print "train_time=", "{:.9f}".format(t2-t1)
        accuracy.append(batch_accuracy.numpy())
        batch_loss = batch_accuracy
        average_loss += batch_loss
        average_acc += batch_accuracy
        t1 = time.time()
        optimizer.apply_gradients(grad(neural_net, x_batch, y_batch))
        learning_handle.train_x = []
        learning_handle.train_y = []
        average_loss /= i
        average_acc /= i
        print("train loss=",
              "{:.9f}".format(average_loss), " accuracy=",
              "{:.4f}".format(average_acc))
        average_loss = 0.
        average_acc = 0.
        i = 0

    if k != 0:
        x_batch=np.stack(learning_handle.test_x, axis=0)
        y_batch=np.stack(learning_handle.test_y, axis=0)
        dataset = tf.data.Dataset.from_tensor_slices(
            (x_batch, y_batch))
        dataset = dataset.repeat().batch(k).prefetch(k)
        dataset_iter = tfe.Iterator(dataset)
        # Iterate through the dataset
        d = dataset_iter.next()
        # Images
        x_batch = d[0]
        # Labels
        y_batch = tf.cast(d[1], dtype=tf.float64)
        t1 = time.time()
        prediction = neural_net(x_batch)
        t2 = time.time()
        print "eval_time=", "{:.9f}".format(t2-t1)
        # Compute the batch accuracy
        batch_accuracy = accuracy_fn(neural_net, prediction, y_batch)
        accuracy.append(batch_accuracy.numpy())
        batch_loss = batch_accuracy
        average_loss += batch_loss
        average_acc += batch_accuracy
        learning_handle.test_x = []
        learning_handle.test_y = []
        average_loss /= i
        average_acc /= i
        print("test loss=",
              "{:.9f}".format(average_loss), " accuracy=",
              "{:.4f}".format(average_acc))
        average_loss = 0.
        average_acc = 0.
        k = 0

    # write the NN
    if model_is_init:
        tf.contrib.eager.save_network_checkpoint(neural_net,checkpoint_prefix)

    file = open("accuracy.txt", "w")
    content = ""
    axis = []
    for i, acc in enumerate(accuracy):
        content += str(acc) + "\n"
        axis.append(i)
    file.write(content)
    file.close()

    plt.plot(axis, accuracy)
    plt.show()

    melissa_server.melissa_server_finalize(ctypes.byref(simu_handle),
                                           ctypes.byref(data))


if __name__ == '__main__':
    main()
